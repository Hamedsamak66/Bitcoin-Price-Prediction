{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjHBoH+4ARL76auk3FphAY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamedsamak66/Bitcoin-Price-Prediction/blob/main/BTC-new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pmdarima\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from pmdarima import auto_arima\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbStK43S_7pC",
        "outputId": "e250d215-3004-4af0-ea78-02050a41743c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pmdarima in /usr/local/lib/python3.10/dist-packages (2.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.4.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (3.0.10)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (0.14.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (2.0.7)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (67.7.2)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pmdarima) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pmdarima) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->pmdarima) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->pmdarima) (0.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.13.2->pmdarima) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Read and preprocess the dataset\n",
        "df = pd.read_csv('/content/sample_data/Dataset.csv')\n",
        "df.rename(columns={df.columns[0]: 'Date'}, inplace=True)\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.set_index('Date', inplace=True)\n",
        "df.fillna(method='ffill', inplace=True)\n",
        "df.fillna(method='bfill', inplace=True)"
      ],
      "metadata": {
        "id": "-tyqQPQFAFiv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numeric columns\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n"
      ],
      "metadata": {
        "id": "39n_-ODTAI_r"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'BTC' is included in numeric_cols if it was excluded for some reason\n",
        "if 'BTC' not in numeric_cols:\n",
        "    numeric_cols.append('BTC')"
      ],
      "metadata": {
        "id": "JIZ8yeo2Aot6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale only the numeric columns\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(df[numeric_cols])"
      ],
      "metadata": {
        "id": "V3WADKQmAumE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences for LSTM\n",
        "def create_sequences(data, seq_length):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data) - seq_length - 1):\n",
        "        X.append(data[i:(i + seq_length), :])\n",
        "        y.append(data[i + seq_length, -1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 60  # Use 60 days of data to predict the next day's BTC price\n",
        "X, y = create_sequences(scaled_data, seq_length)"
      ],
      "metadata": {
        "id": "VixTQdppA15I"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "KBIhTG5bA66b"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Build and train the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFF58KMtBAZr",
        "outputId": "8e711af6-51d3-42c1-86d6-ac3a9ed34d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "46/46 [==============================] - 56s 86ms/step - loss: 0.0151 - val_loss: 0.0047\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 3s 58ms/step - loss: 0.0055 - val_loss: 0.0026\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 0.0049 - val_loss: 0.0020\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.0036 - val_loss: 0.0017\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 3s 74ms/step - loss: 0.0042 - val_loss: 0.0019\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 3s 61ms/step - loss: 0.0034 - val_loss: 0.0011\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 3s 58ms/step - loss: 0.0030 - val_loss: 9.1908e-04\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.0028 - val_loss: 9.4844e-04\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 4s 84ms/step - loss: 0.0026 - val_loss: 0.0012\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 3s 57ms/step - loss: 0.0027 - val_loss: 0.0014\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.0029 - val_loss: 9.6881e-04\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 3s 57ms/step - loss: 0.0020 - val_loss: 0.0011\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 3s 61ms/step - loss: 0.0024 - val_loss: 7.3209e-04\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 4s 79ms/step - loss: 0.0021 - val_loss: 7.9564e-04\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.0021 - val_loss: 0.0036\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.0024 - val_loss: 6.2873e-04\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.0020 - val_loss: 7.2521e-04\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 3s 68ms/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 0.0019 - val_loss: 9.3325e-04\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 2s 53ms/step - loss: 0.0019 - val_loss: 5.8457e-04\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.0018 - val_loss: 8.5473e-04\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 3s 55ms/step - loss: 0.0018 - val_loss: 0.0012\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 4s 77ms/step - loss: 0.0017 - val_loss: 6.9703e-04\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 3s 59ms/step - loss: 0.0020 - val_loss: 9.5120e-04\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 2s 52ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 2s 52ms/step - loss: 0.0016 - val_loss: 8.3234e-04\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 2s 52ms/step - loss: 0.0018 - val_loss: 7.0349e-04\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 3s 75ms/step - loss: 0.0017 - val_loss: 0.0010\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 3s 58ms/step - loss: 0.0016 - val_loss: 5.7201e-04\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 2s 54ms/step - loss: 0.0014 - val_loss: 7.2328e-04\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 2s 51ms/step - loss: 0.0015 - val_loss: 7.1777e-04\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 2s 52ms/step - loss: 0.0014 - val_loss: 5.9714e-04\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 3s 73ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 3s 60ms/step - loss: 0.0017 - val_loss: 8.7486e-04\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 2s 51ms/step - loss: 0.0017 - val_loss: 0.0023\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 2s 51ms/step - loss: 0.0018 - val_loss: 5.0401e-04\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 2s 52ms/step - loss: 0.0013 - val_loss: 5.1582e-04\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 3s 73ms/step - loss: 0.0016 - val_loss: 5.9535e-04\n",
            "Epoch 39/50\n",
            "29/46 [=================>............] - ETA: 0s - loss: 0.0012"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Evaluate the LSTM model\n",
        "y_pred_lstm = model.predict(X_test)\n",
        "\n",
        "# Inverse transform the predictions and actual values\n",
        "y_pred_lstm = scaler.inverse_transform(np.concatenate((np.zeros((y_pred_lstm.shape[0], len(numeric_cols) - 1)), y_pred_lstm), axis=1))[:, -1]\n",
        "y_test_lstm = scaler.inverse_transform(np.concatenate((np.zeros((y_test.shape[0], len(numeric_cols) - 1)), y_test.reshape(-1, 1)), axis=1))[:, -1]\n",
        "\n",
        "# Calculate R-squared and MSE for LSTM model\n",
        "r2_lstm = r2_score(y_test_lstm, y_pred_lstm)\n",
        "mse_lstm = mean_squared_error(y_test_lstm, y_pred_lstm)\n",
        "\n",
        "print(f'LSTM Model - R-squared: {r2_lstm}, MSE: {mse_lstm}')"
      ],
      "metadata": {
        "id": "Vp3-ApvTCAH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Build and train the Linear Regression model\n",
        "# Reshape data for Linear Regression\n",
        "X_lr = scaled_data[:, :-1]  # Use all columns except the last one (BTC price) for features\n",
        "y_lr = scaled_data[:, -1]   # Use BTC price as the target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_lr, y_lr, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Linear Regression model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_lr, y_train_lr)"
      ],
      "metadata": {
        "id": "EvDvgUBdCRv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Evaluate the Linear Regression model\n",
        "y_pred_lr = lr_model.predict(X_test_lr)\n",
        "\n",
        "# Inverse transform the predictions and actual values\n",
        "y_pred_lr = scaler.inverse_transform(np.concatenate((np.zeros((y_pred_lr.shape[0], len(numeric_cols) - 1)), y_pred_lr.reshape(-1, 1)), axis=1))[:, -1]\n",
        "y_test_lr = scaler.inverse_transform(np.concatenate((np.zeros((y_test_lr.shape[0], len(numeric_cols) - 1)), y_test_lr.reshape(-1, 1)), axis=1))[:, -1]\n",
        "\n",
        "# Calculate R-squared and MSE for Linear Regression model\n",
        "r2_lr = r2_score(y_test_lr, y_pred_lr)\n",
        "mse_lr = mean_squared_error(y_test_lr, y_pred_lr)\n",
        "\n",
        "print(f'Linear Regression Model - R-squared: {r2_lr}, MSE: {mse_lr}')\n"
      ],
      "metadata": {
        "id": "oQY2gGZlCbyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Build and train the ARIMA model using auto_arima\n",
        "# ARIMA model works on univariate time series, use only the BTC price column\n",
        "btc_prices = df['BTC'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(len(btc_prices) * 0.8)\n",
        "train_btc, test_btc = btc_prices[:train_size], btc_prices[train_size:]\n",
        "\n",
        "# Use auto_arima to find the best parameters for ARIMA\n",
        "arima_model = auto_arima(train_btc, seasonal=False, stepwise=True, suppress_warnings=True)\n",
        "arima_order = arima_model.order\n",
        "print(f'Best ARIMA order: {arima_order}')\n",
        "\n",
        "# Train the ARIMA model with the best order found\n",
        "arima_model = ARIMA(train_btc, order=arima_order)\n",
        "arima_model_fit = arima_model.fit()\n",
        "\n"
      ],
      "metadata": {
        "id": "-qJJ_ZchCvdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 7: Evaluate the ARIMA model\n",
        "pred_start = len(train_btc)\n",
        "pred_end = len(btc_prices) - 1\n",
        "y_pred_arima = arima_model_fit.predict(start=pred_start, end=pred_end, dynamic=False)\n",
        "\n",
        "# Calculate R-squared and MSE for ARIMA model\n",
        "r2_arima = r2_score(test_btc, y_pred_arima)\n",
        "mse_arima = mean_squared_error(test_btc, y_pred_arima)\n",
        "\n",
        "print(f'ARIMA Model - R-squared: {r2_arima}, MSE: {mse_arima}')\n"
      ],
      "metadata": {
        "id": "RadOH9HvC0Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Plot the R-squared values for comparison\n",
        "models = ['LSTM', 'Linear Regression', 'ARIMA']\n",
        "r2_values = [r2_lstm, r2_lr, r2_arima]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, r2_values, color=['blue', 'green', 'red'])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('R-squared')\n",
        "plt.title('Comparison of R-squared values for different models')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dvSsqexWLWDU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}